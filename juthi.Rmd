---
title: "capstone"
author: "Juthi Dewan"
date: "4/19/2021"
output: html_document
---

```{r}
library(data.table)
library(dplyr)
library(tidyverse)
library(sf)
library(tidyverse)         # for reading in data, graphing, and cleaning
library(tidymodels)        # for modeling ... tidily
library(glmnet)            # for regularized regression, including LASSO
library(naniar)            # for examining missing values (NAs)
library(lubridate)         # for date manipulation
library(moderndive)        # for King County housing data
library(vip)               # for variable importance plots
library(rmarkdown)         # for paged tables
theme_set(theme_minimal()) # my favorite ggplot2 theme :)



library(themis)            # for step functions for unbalanced data
library(stacks)            # for stacking models
library(lubridate)         # for date manipulation
library(moderndive)        # for King County housing data
library(vip)               # for variable importance plots
library(DALEX)             # for model interpretation  
library(DALEXtra)          # for extension of DALEX
library(patchwork)         # for combining plots nicely
theme_set(theme_minimal()) # Lisa's favorite theme


library(scales)
library(plotly)
library(gridExtra)
library(tidytext)
library(modelr)
library(caret)
library(ROSE)
library(glmnet)
library(rpart)
library(rpart.plot)
library(randomForest)
options(warn = -1)
```

```{r}
cars <- read_csv("small_accidents.csv", col_types = cols(.default = col_character())) %>% 
  type_convert()
  
cars %>%
  group_by(State) %>%
  summarize(Count=n()) %>%
  arrange(desc(Count))

cars %>%
  group_by(Severity) %>%
  summarize(Count=n()) %>%
  arrange(desc(Count))

cars %>%
  group_by(Stop) %>%
  summarize(Count=n()) %>%
  arrange(desc(Count))

cars %>%
  group_by(State) %>%
  summarize(Count=n()) %>%
  arrange(desc(Count))

cars %>%
  group_by(Weather_Condition) %>%
  summarize(Count=n()) %>%
  arrange(desc(Count))

weather <-
  cars %>%
  group_by(Weather_Condition) %>%
  summarize(Count=n()) %>%
  arrange(desc(Count))
```

```{r}
ggplot(cars, aes(as.factor(Weather_Condition), ..prop.., group = Severity)) + 
  geom_bar(aes(fill = Severity), position = "dodge") +
  scale_y_continuous(labels = percent) +
  theme(axis.text.x = element_text(angle = 60, vjust = 0.6))
```


#Pre-processing

```{r}
cars %>% summarise_all(~ mean(is.na(.))) %>% 
  pivot_longer(1:49, names_to = "Variables to drop", values_to = "NA proportion") %>% 
  filter(`NA proportion` >= 0.5)

#do some reporting for why you're choosing to leave them out 

drop_na_cols <- c("End_Lat", "End_Lng", "Number")

not_useful <- c("ID", "Source", "Timezone", "Airport_Code", "Weather_Timestamp","Wind_Direction", "Description", "Bump", "Traffic_Calming", "Give_Way", "No_Exit", "Railway", "Roundabout", "Station", "Stop", "Amenity", "Street", "Zipcode", "Country", "Turning_Loop")

#eliminated due to near-zero variance, step function can also get rid of them. 

traffic <- 
  cars %>% 
  select(-all_of(drop_na_cols), -all_of(not_useful))


traffic <-  traffic %>%
  rename("Distance" = `Distance(mi)`, "Temperature" = `Temperature(F)`, "Humidity" = `Humidity(%)`, 
         "Pressure" = `Pressure(in)`, "Visibility" = `Visibility(mi)`, "Wind_Speed" = `Wind_Speed(mph)`)

traffic$Severity <- as.character(traffic$Severity)

traffic <-
  traffic %>% 
  add_n_miss() %>% 
  filter(n_miss_all == 0) %>% 
  select(-n_miss_all)

traffic <- traffic %>%
  mutate("Status" = factor(ifelse(Severity == "3" | Severity == "4", "Severe", "Not Severe"), 
                           levels = c("Not Severe", "Severe")))
```


```{r}
traffic_time <- traffic %>%
  mutate(Duration = (End_Time - Start_Time)) %>%
  # accident duration should be positive
  filter(!(Duration < 0)) %>%
  separate(Start_Time, into = c("Date", "Time"), sep = " ") %>%
  mutate("Year" = str_sub(Date, 1, 4), "Month" = str_sub(Date, 6, 7), "Day" = str_sub(Date, 9, 10),
         "Wday" = as.character(wday(Date))) %>%
  mutate("Hour" = str_sub(Time,1,2)) %>%
  mutate("Status" = factor(ifelse(Severity == "3" | Severity == "4", "Severe", "Not Severe"), 
                           levels = c("Not Severe", "Severe"))) %>% 
  select(-c("Date", "Time", "End_Time")) %>%
  select(TMC, Severity, Year, Month, Day, Hour, Wday, Duration, everything())

```



```{r}
#Drop levels that have less than 20 observations
weather_to_drop <- 
  traffic_time %>% 
    count(Weather_Condition) %>% 
    filter(n < 20) %>% 
    select(Weather_Condition)

weather_to_drop <- 
  weather_to_drop$Weather_Condition %>% 
    unlist()

traffic_weather <- traffic_time %>% 
  filter(!(Weather_Condition %in% weather_to_drop)) %>% 
  mutate(Weather_Condition = factor(Weather_Condition)) 

traffic_final <- traffic_weather

traffic_final %>%
  group_by(Weather_Condition) %>%
  summarize(Count=n()) %>%
  arrange(desc(Count))
```


```{r, eval = FALSE}
write_csv(x = traffic_final, "/Users/francosalinas/Desktop/ADV_DATA/final_project/traffic_final.csv")
```


```{r}
ggplot(cars, aes(Wind_Direction, ..prop.., group = Severity)) +
  geom_bar(aes(fill = Severity), position = "dodge") +
  scale_y_continuous(labels = percent) +
  theme(axis.text.x = element_text(angle = 60, vjust = 0.6))
```

```{r}
ggplot(cars, aes(as.factor(Station), ..prop.., group = Severity)) + 
  geom_bar(aes(fill = Severity), position = "dodge") +
  scale_y_continuous(labels = percent) +
  theme(axis.text.x = element_text(angle = 60, vjust = 0.6))
```


# Traffic signal is a good indicator
# Bump is a bad indicator bc there are no accidents recorded when there is a bump.
# bad indicators : Bump, Traffic_Calming, Give_Way, No_Exit, Railway, Roundabout, Station, Stop
# good indicators : Crossing, Junction, Sunrise_Sunset, Civil_Twilight, 

```{r}
ca <- 
  traffic_final %>%
  filter(State=="CA")

tx <-
  traffic_final %>%
  filter(State=="TX")

fl <-
  traffic_final %>%
  filter(State=="FL")

sc <-
  traffic_final %>%
  filter(State=="SC")

nc <-
  traffic_final %>%
  filter(State=="NC")
```


```{r}
nc %>% 
  select(where(is.numeric)) %>% 
  pivot_longer(cols = everything(),
               names_to = "variable", 
               values_to = "value") %>% 
  ggplot(aes(x = value)) +
  geom_histogram(bins = 30) +
  facet_wrap(vars(variable), 
             scales = "free")
```

> Humidity, Wind_Chill and Temperature are left skewed, Wind_Speed is right skewed.


```{r}
nc %>% 
  add_n_miss() %>% 
  count(n_miss_all)

ca %>%
  add_n_miss() %>% 
  count(n_miss_all)
```



### Modelling 

```{r}
#north carolina
nc_mod <- nc %>% 
  mutate(Status = as.factor(Status)) %>% 
  mutate(across(where(is.character), as.factor)) %>% 
  select(-c(State, Severity)) %>%
  # select(-arrival_date_year,
  #        -reservation_status,
  #        -reservation_status_date) %>% 
  add_n_miss() %>% 
  filter(n_miss_all == 0) %>% 
  select(-n_miss_all)

 nc_mod$Crossing <- as.factor(nc_mod$Crossing)
 nc_mod$Junction <- as.factor(nc_mod$Junction)
 nc_mod$Traffic_Signal <- as.factor(nc_mod$Traffic_Signal)
 nc_mod$Month <- as.numeric(nc_mod$Month)
 nc_mod$Wday <- as.numeric(nc_mod$Wday)
nc_mod$Hour <- as.numeric(nc_mod$Hour)
  nc_mod$Duration <- as.numeric(nc_mod$Duration)

set.seed(327) #for reproducibility

# Randomly assigns 50% of the data to training.
nc_split <- initial_split(nc_mod, 
                             prop = .50)
nc_split

nc_training <- training(nc_split)
nc_testing <- testing(nc_split)

#creating recipe
nc_recipe <- recipe(Status ~ .,
                       data = nc_training) %>% 
  step_mutate(County, 
              County = fct_lump_n(County, n = 5)) %>% 
  step_mutate(City, 
              City = fct_lump_n(City, n = 5)) %>% 
  step_normalize(all_predictors(),
                -all_nominal(),
                -all_outcomes()) %>% 
  step_dummy(all_nominal(),
             -all_outcomes()) 


nc_recipe %>% 
  prep() %>% #applied to training data by default since that's in the recipe
  juice() 


#setting up lasso for north carolina
nc_lasso_mod <- 
  logistic_reg(mixture = 1) %>% 
  set_engine("glmnet") %>% 
  set_args(penalty = tune()) %>% 
  set_mode("classification")

nc_lasso_wf <- 
  workflow() %>% 
  add_recipe(nc_recipe) %>% 
  add_model(nc_lasso_mod)

nc_lasso_wf

nc_cv <- vfold_cv(nc_training, v = 3)
penalty_grid <- grid_regular(penalty(),
                             levels = 5)
penalty_grid 

nc_lasso_tune <- 
  nc_lasso_wf %>% 
  tune_grid(
    resamples = nc_cv,
    grid = penalty_grid
    )

 nc_lasso_tune %>%
   collect_metrics()
 
best_param_nc <- nc_lasso_tune %>% 
  select_best(metric = "accuracy")
best_param_nc

nc_final_lasso <- nc_lasso_wf %>% 
  finalize_workflow(best_param_nc) %>% 
  fit(data = nc_training)

nc_final_lasso %>% 
  pull_workflow_fit() %>% 
  tidy()

nc_final_lasso %>% 
  pull_workflow_fit() %>% 
  vip()
```

```{r}
#cali 

ca_mod <- ca %>% 
  mutate(Status = as.factor(Status)) %>% 
  mutate(across(where(is.character), as.factor)) %>% 
  select(-c(State, Severity)) %>%
  # select(-arrival_date_year,
  #        -reservation_status,
  #        -reservation_status_date) %>% 
  add_n_miss() %>% 
  filter(n_miss_all == 0) %>% 
  select(-n_miss_all)

ca_mod

 ca_mod$Crossing <- as.factor(ca_mod$Crossing)
 ca_mod$Junction <- as.factor(ca_mod$Junction)
 ca_mod$Traffic_Signal <- as.factor(ca_mod$Traffic_Signal)
 ca_mod$Month <- as.numeric(ca_mod$Month)
 ca_mod$Wday <- as.numeric(ca_mod$Wday)
 ca_mod$Hour <- as.numeric(ca_mod$Hour)
  ca_mod$Duration <- as.numeric(ca_mod$Duration)

set.seed(327) #for reproducibility

# Randomly assigns 75% of the data to training.
ca_split <- initial_split(ca_mod, 
                             prop = .50)
ca_split

ca_training <- training(ca_split)
ca_testing <- testing(ca_split)

#creating recipe
ca_recipe <- recipe(Status ~ .,
                       data = ca_training) %>% 
  step_mutate(County, 
              County = fct_lump_n(County, n = 5)) %>% 
  step_mutate(City, 
              City = fct_lump_n(City, n = 5)) %>% 
  step_normalize(all_predictors(),
                -all_nominal(),
                -all_outcomes()) %>% 
  step_dummy(all_nominal(),
             -all_outcomes()) 


ca_recipe %>% 
  prep() %>% #applied to training data by default since that's in the recipe
  juice() 


#setting up lasso for north carolina
ca_lasso_mod <- 
  logistic_reg(mixture = 1) %>% 
  set_engine("glmnet") %>% 
  set_args(penalty = tune()) %>% 
  set_mode("classification")

ca_lasso_wf <- 
  workflow() %>% 
  add_recipe(ca_recipe) %>% 
  add_model(ca_lasso_mod)

ca_lasso_wf

ca_cv <- vfold_cv(ca_training, v = 3)
penalty_grid <- grid_regular(penalty(),
                             levels = 10)
penalty_grid 

ca_lasso_tune <- 
  ca_lasso_wf %>% 
  tune_grid(
    resamples = ca_cv,
    grid = penalty_grid
    )

ca_lasso_tune

ca_lasso_tune %>%
    collect_metrics()

best_param_ca <- ca_lasso_tune %>% 
  select_best(metric = "accuracy")
best_param_ca

ca_final_lasso <- ca_lasso_wf %>% 
  finalize_workflow(best_param_ca) %>% 
  fit(data = ca_training)

ca_final_lasso %>% 
  pull_workflow_fit() %>% 
  tidy()

ca_final_lasso %>% 
  pull_workflow_fit() %>% 
  vip()
```



```{r}
#texas 

tx_mod <- tx %>% 
  mutate(Status = as.factor(Status)) %>% 
  mutate(across(where(is.character), as.factor)) %>% 
  select(-c(Start_Time, End_Time, State, Severity)) %>%
  # select(-arrival_date_year,
  #        -reservation_status,
  #        -reservation_status_date) %>% 
  add_n_miss() %>% 
  filter(n_miss_all == 0) %>% 
  select(-n_miss_all)

tx_mod

 tx_mod$Crossing <- as.factor(tx_mod$Crossing)
 tx_mod$Junction <- as.factor(tx_mod$Junction)
 tx_mod$Traffic_Signal <- as.factor(tx_mod$Traffic_Signal)

set.seed(327) #for reproducibility

# Randomly assigns 75% of the data to training.
tx_split <- initial_split(tx_mod, 
                             prop = .50)
tx_split

tx_training <- training(tx_split)
tx_testing <- testing(tx_split)

#creating recipe
tx_recipe <- recipe(Status ~ .,
                       data = tx_training) %>% 
  # step_mutate(County, 
  #             County = fct_lump_n(County, n = 5)) %>% 
  # step_mutate(City, 
  #             City = fct_lump_n(City, n = 5)) %>% 
  step_normalize(all_predictors(),
                -all_nominal(),
                -all_outcomes()) %>% 
  step_dummy(all_nominal(),
             -all_outcomes()) 


tx_recipe %>% 
  prep() %>% #applied to training data by default since that's in the recipe
  juice() 


#setting up lasso for north carolina
tx_lasso_mod <- 
  logistic_reg(mixture = 1) %>% 
  set_engine("glmnet") %>% 
  set_args(penalty = tune()) %>% 
  set_mode("classification")

tx_lasso_wf <- 
  workflow() %>% 
  add_recipe(tx_recipe) %>% 
  add_model(tx_lasso_mod)

tx_lasso_wf

tx_cv <- vfold_cv(tx_training, v = 3)
penalty_grid <- grid_regular(penalty(),
                             levels = 10)
penalty_grid 

tx_lasso_tune <- 
  tx_lasso_wf %>% 
  tune_grid(
    resamples = tx_cv,
    grid = penalty_grid
    )

tx_lasso_tune

tx_lasso_tune %>%
    collect_metrics()

best_param_tx <- tx_lasso_tune %>% 
  select_best(metric = "accuracy")
best_param_tx

tx_final_lasso <- tx_lasso_wf %>% 
  finalize_workflow(best_param_tx) %>% 
  fit(data = tx_training)

tx_final_lasso %>% 
  pull_workflow_fit() %>% 
  tidy()

tx_final_lasso %>% 
  pull_workflow_fit() %>% 
  vip()
```

```{r}
#florida 

fl_mod <- fl %>% 
  mutate(Status = as.factor(Status)) %>% 
  mutate(across(where(is.character), as.factor)) %>% 
  select(-c(Start_Time, End_Time, State, Severity)) %>%
  # select(-arrival_date_year,
  #        -reservation_status,
  #        -reservation_status_date) %>% 
  add_n_miss() %>% 
  filter(n_miss_all == 0) %>% 
  select(-n_miss_all)

fl_mod

 fl_mod$Crossing <- as.factor(fl_mod$Crossing)
 fl_mod$Junction <- as.factor(fl_mod$Junction)
 fl_mod$Traffic_Signal <- as.factor(fl_mod$Traffic_Signal)

set.seed(327) #for reproducibility

# Randomly assigns 75% of the data to training.
fl_split <- initial_split(fl_mod, 
                             prop = .50)
fl_split

fl_training <- training(fl_split)
fl_testing <- testing(fl_split)

#creating recipe
fl_recipe <- recipe(Status ~ .,
                       data = fl_training) %>% 
  step_mutate(County, 
              County = fct_lump_n(County, n = 5)) %>% 
  step_mutate(City, 
              City = fct_lump_n(City, n = 5)) %>% 
  step_normalize(all_predictors(),
                -all_nominal(),
                -all_outcomes()) %>% 
  step_dummy(all_nominal(),
             -all_outcomes()) 


fl_recipe %>% 
  prep() %>% #applied to training data by default since that's in the recipe
  juice() 


#setting up lasso for north carolina
fl_lasso_mod <- 
  logistic_reg(mixture = 1) %>% 
  set_engine("glmnet") %>% 
  set_args(penalty = tune()) %>% 
  set_mode("classification")

fl_lasso_wf <- 
  workflow() %>% 
  add_recipe(fl_recipe) %>% 
  add_model(fl_lasso_mod)

fl_lasso_wf

tx_cv <- vfold_cv(tx_training, v = 3)
penalty_grid <- grid_regular(penalty(),
                             levels = 10)
penalty_grid 

fl_lasso_tune <- 
  fl_lasso_wf %>% 
  tune_grid(
    resamples = tx_cv,
    grid = penalty_grid
    )

fl_lasso_tune

fl_lasso_tune %>%
    collect_metrics()

best_param_fl <- fl_lasso_tune %>% 
  select_best(metric = "accuracy")
best_param_fl

fl_final_lasso <- fl_lasso_wf %>% 
  finalize_workflow(best_param_fl) %>% 
  fit(data = fl_training)

fl_final_lasso %>% 
  pull_workflow_fit() %>% 
  tidy()

fl_final_lasso %>% 
  pull_workflow_fit() %>% 
  vip()
```


```{r}

```

```{r}
#modeling pre-process for traffic_final

traffic_mod <- traffic_final %>% 
  mutate(Status = as.factor(Status)) %>% 
  mutate(across(where(is.character), as.factor)) %>% 
  select(-c(State, Severity, Year, Day)) %>%
  # select(-arrival_date_year,
  #        -reservation_status,
  #        -reservation_status_date) %>% 
  add_n_miss() %>% 
  filter(n_miss_all == 0) %>% 
  select(-n_miss_all)


traffic_mod$Crossing <- as.factor(traffic_mod$Crossing)
traffic_mod$Month <- as.numeric(traffic_mod$Month)
traffic_mod$Wday <- as.numeric(traffic_mod$Wday)
traffic_mod$Hour <- as.numeric(traffic_mod$Hour)
traffic_mod$Duration <- as.numeric(traffic_mod$Duration)
traffic_mod$Junction <- as.factor(traffic_mod$Junction)
traffic_mod$Traffic_Signal <- as.factor(traffic_mod$Traffic_Signal)
 

set.seed(494) #for reproducibility

# Randomly assigns 75% of the data to training.
traffic_split <- initial_split(traffic_mod, 
                             prop = .50)
traffic_split

traffic_training <- training(traffic_split)
traffic_testing <- testing(traffic_split)
```

```{r}
#lasso
set.seed(494)

lasso_recipe <-
  recipe(Status ~ .,
         data = traffic_training) %>%
  step_mutate(County,
               County = fct_lump_n(County, n = 5)) %>%
   step_mutate(City,
               City = fct_lump_n(City, n = 5)) %>%
  step_normalize(all_predictors(),
                 -all_nominal(),
                 -all_outcomes()) %>%
  step_dummy(all_nominal(),
             -all_outcomes())

lasso_recipe %>%
  prep() %>%
  juice()

lasso_mod <-
  logistic_reg(mixture = 1) %>%
  set_engine("glmnet") %>%
  set_args(penalty = tune()) %>%
  set_mode("classification")

lasso_wf <-
  workflow() %>%
  add_recipe(lasso_recipe) %>%
  add_model(lasso_mod)

set.seed(494) #for reproducible 5-fold
traffic_cv <- vfold_cv(traffic_training,
                       v = 5)

penalty_grid <- grid_regular(penalty(),
                             levels = 10)

# add ctrl_grid - assures predictions and workflows are saved
ctrl_grid <- control_stack_resamples()

metric <- metric_set(accuracy)

# tune the model
lasso_tune <-
  lasso_wf %>%
  tune_grid(
    resamples = traffic_cv,
    grid = penalty_grid,
    control = ctrl_grid
    )

lasso_tune %>%
  collect_metrics()
```



```{r}
# #lasso
# traffic_recipe <- recipe(Status ~ .,
#                        data = traffic_training) %>%
#   step_mutate(County,
#               County = fct_lump_n(County, n = 5)) %>%
#   step_mutate(City,
#               City = fct_lump_n(City, n = 5)) %>%
#   step_normalize(all_predictors(),
#                 -all_nominal(),
#                 -all_outcomes()) %>%
#   step_dummy(all_nominal(),
#              -all_outcomes())
# 
# traffic_recipe %>%
#   prep() %>% #applied to training data by default since that's in the recipe
#   juice()
# 
# 
# #setting up lasso for north carolina
# traffic_lasso_mod <-
#   logistic_reg(mixture = 1) %>%
#   set_engine("glmnet") %>%
#   set_args(penalty = tune()) %>%
#   set_mode("classification")
# 
# 
# traffic_lasso_wf <-
#   workflow() %>%
#   add_recipe(traffic_recipe) %>%
#   add_model(traffic_lasso_mod)
# 
# traffic_lasso_wf
# 
# 
# set.seed(494) #for reproducible 5-fold
# traffic_cv <- vfold_cv(traffic_training,
#                        v = 5)
# 
#  penalty_grid <- grid_regular(penalty(),
#                               levels = 10)
# 
# # add ctrl_grid - assures predictions and workflows are saved
# ctrl_grid <- control_stack_grid()
# 
# 
# traffic_lasso_tune <-
#   traffic_lasso_wf %>%
#   tune_grid(
#     resamples = traffic_cv,
#     grid = penalty_grid, 
#     control = ctrl_grid
#     )
# 
# traffic_lasso_tune
# 
# traffic_lasso_tune %>%
#     collect_metrics()

# best_param_traffic <- traffic_lasso_tune %>%
#   select_best(metric = "accuracy")
# best_param_traffic
# 
# traffic_final_lasso <- traffic_lasso_wf %>%
#   finalize_workflow(best_param_traffic) %>%
#   fit(data = traffic_training)
# 
# traffic_final_lasso %>%
#   pull_workflow_fit() %>%
#   tidy()
# 
# traffic_final_lasso %>%
#   pull_workflow_fit() %>%
#   vip()
# 
# 
# traffic_mod %>%
#   count(Status)
```


```{r}
#classification rf 
set.seed(494)

rf_recipe <- 
  recipe(Status ~ .,
         data = traffic_training) %>% 
  step_mutate_at(all_numeric(), 
                 fn = ~as.numeric(.))


rf_recipe %>% 
  prep() %>% 
  juice()


rf_model <-
  rand_forest(mtry = tune(),
              min_n = tune(),
              trees = 10) %>%
  set_mode("classification") %>%
  set_engine("ranger")


rf_workflow <-
  workflow() %>% 
  add_recipe(rf_recipe) %>% 
  add_model(rf_model)


rf_penalty_grid <- 
  grid_regular(finalize(mtry(),
                        traffic_training %>%
                          select(-Status)),
               min_n(),
               levels = 3)


# traffic_cv <- vfold_cv(traffic_training,
#                        v = 5)

rf_tune <- 
  rf_workflow %>% 
  tune_grid(
    resamples = traffic_cv,
    grid = rf_penalty_grid,
    control = ctrl_grid
  )

rf_tune %>%
  collect_metrics()
```




```{r}
#decision trees
set.seed(494)

tree_model <- 
  decision_tree() %>% 
  set_mode("classification") %>% 
  set_engine("rpart")

tree_workflow <-
  workflow() %>% 
  add_recipe(rf_recipe) %>% 
  add_model(tree_model)

tree_fit <- tree_workflow %>% 
  fit_resamples(traffic_cv, 
                # metrics = metric,
                control = ctrl_grid)

collect_metrics(tree_fit)
```

```{r}
# set.seed(494)
# 
# knn_mod <-
#   nearest_neighbor(
#     neighbors = tune("k")
#   ) %>%
#   set_engine("kknn") %>% 
#   set_mode("classification")
# 
# # create the workflow
# knn_wf <- 
#   workflow() %>% 
#   add_model(knn_mod) %>%
#   add_recipe(rf_recipe)
# 
# # tune it using 4 tuning parameters
# knn_tune <- 
#   knn_wf %>% 
#   tune_grid(
#     traffic_cv,
#     grid = 4,
#     control = ctrl_grid
#   )
```


# model stacking 
```{r}
lasso_tune %>%
  collect_metrics()

rf_tune %>%
  collect_metrics()

tree_fit %>%
  collect_metrics()
```

<<<<<<< HEAD
```{r}
lending_stack <-
  stacks() %>%
  add_candidates(lasso_tune) %>%
  add_candidates(rf_tune) %>%
  add_candidates(tree_fit)
```

```{r}
lending_blend <-
  lending_stack %>% 
  blend_predictions()
lending_blend
```

```{r}
autoplot(lending_blend)
```








