---
title: "Behind scenes of car accident severity prediction"
output: html_document
---

---
title: "Prediction of the Severity of Car Accidents"
author: "Juthi Dewan, Coco Li, Franco Salinas"
date: "5/07/2021"
# runtime: shiny
output:
  html_document:
    toc: true
    toc_float: true
    df_print: paged
    code_download: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message=FALSE, warning=FALSE)
```

```{r}
library(data.table)
library(dplyr)
library(tidyverse)
library(sf)
library(tidyverse)         # for reading in data, graphing, and cleaning
library(tidymodels)        # for modeling ... tidily
library(glmnet)            # for regularized regression, including LASSO
library(naniar)            # for examining missing values (NAs)
library(lubridate)         # for date manipulation
library(moderndive)        # for King County housing data
library(vip)               # for variable importance plots
library(rmarkdown)         # for paged tables
library(themis)            # for step functions for unbalanced data
library(stacks)            # for stacking models
library(DALEX)             # for model interpretation  
library(DALEXtra)          # for extension of DALEX
library(patchwork)         # for combining plots nicely
library(scales)
library(plotly)
library(gridExtra)
library(tidytext)
library(modelr)
library(caret)
library(ROSE)
library(glmnet)
library(rpart)
library(rpart.plot)
library(randomForest)
library(shiny)
library(bslib)
options(warn = -1)
theme_set(theme_minimal()) # my favorite ggplot2 theme :)
```



```{r}
cars <- read_csv("small_accidents.csv", col_types = cols(.default = col_character())) %>%
  type_convert()

cars %>%
  group_by(City) %>%
  summarize(Count=n()) %>%
  arrange(desc(Count)) %>%
  head(1000)
```


# Introduction

The Fatality Analysis Reporting System indicated that an estimate of 8870 people died in motor vehicle traffic crashes in the second quarter of 2020 (NHTSA, 2020). This analysis is intended to bring light to the main environmental conditions that are associated with the severity of a car accident. For the purpose of this study we defined severity as the accident's impact on traffic.

# Data

The data we used has 47 variables and 3 million observations for different car accidents. The data was collected from February 2016 to December 2020 for the 49 states of the US. The data base has been constructed partly by Moosavi, Sobhan, Mohammad Hossein Samavatian, Srinivasan Parthasarathy, and Rajiv Ramnath as “A Countrywide Traffic Accident Dataset” (2019). The other part of the data base was constructed by Moosavi, Sobhan, Mohammad Hossein Samavatian, Srinivasan Parthasarathy, Radu Teodorescu, and Rajiv Ramnath for their database “Accident Risk Prediction based on Heterogeneous Sparse Data: New Dataset and Insights.”

# Models

Using this data set, we predicted the Severity of an accident using stacked LASSO, Forest and classification three. Stacking combines predictions from many different models into a "super" predictor. In this case we would be averaging the predictions of the LASSO, Forest and classification three.

# Pre-processing

```{r, echo = TRUE}
cars %>% summarise_all(~ mean(is.na(.))) %>%
  pivot_longer(1:49, names_to = "Variables to drop", values_to = "NA proportion") %>%
  filter(`NA proportion` >= 0.5)


drop_na_cols <- c("End_Lat", "End_Lng", "Number")

not_useful <- c("ID", "Source", "Timezone", "Airport_Code", "Weather_Timestamp","Wind_Direction", "Description", "Bump", "Traffic_Calming", "Give_Way", "No_Exit", "Railway", "Roundabout", "Station", "Stop", "Amenity", "Street", "Zipcode", "Country", "Turning_Loop", "County", "TMC")


traffic <-
  cars %>%
  select(-all_of(drop_na_cols), -all_of(not_useful))

p1 <- ggplot(cars, aes(as.factor(Station), ..prop.., group = Severity)) +
  geom_bar(aes(fill = Severity), position = "dodge") +
  scale_y_continuous(labels = percent) +
  theme(axis.text.x = element_text(angle = 60, vjust = 0.6))
 
p2 <-  ggplot(cars, aes(Turning_Loop, ..prop.., group = Severity)) +
  geom_bar(aes(fill = Severity), position = "dodge") +
  scale_y_continuous(labels = percent) +
  theme(axis.text.x = element_text(angle = 60, vjust = 0.6))

p3 <- ggplot(cars, aes(Country, ..prop.., group = Severity)) +
  geom_bar(aes(fill = Severity), position = "dodge") +
  scale_y_continuous(labels = percent) +
  theme(axis.text.x = element_text(angle = 60, vjust = 0.6))

p4 <- ggplot(cars, aes(Amenity, ..prop.., group = Severity)) +
  geom_bar(aes(fill = Severity), position = "dodge") +
  scale_y_continuous(labels = percent) +
  theme(axis.text.x = element_text(angle = 60, vjust = 0.6))

p5 <- ggplot(cars, aes(Stop, ..prop.., group = Severity)) +
  geom_bar(aes(fill = Severity), position = "dodge") +
  scale_y_continuous(labels = percent) +
  theme(axis.text.x = element_text(angle = 60, vjust = 0.6))

p6 <- ggplot(cars, aes(Station, ..prop.., group = Severity)) +
  geom_bar(aes(fill = Severity), position = "dodge") +
  scale_y_continuous(labels = percent) +
  theme(axis.text.x = element_text(angle = 60, vjust = 0.6))

p7 <- ggplot(cars, aes(Roundabout, ..prop.., group = Severity)) +
  geom_bar(aes(fill = Severity), position = "dodge") +
  scale_y_continuous(labels = percent) +
  theme(axis.text.x = element_text(angle = 60, vjust = 0.6))

p8 <- ggplot(cars, aes(Railway, ..prop.., group = Severity)) +
  geom_bar(aes(fill = Severity), position = "dodge") +
  scale_y_continuous(labels = percent) +
  theme(axis.text.x = element_text(angle = 60, vjust = 0.6))

p9 <- ggplot(cars, aes(No_Exit, ..prop.., group = Severity)) +
  geom_bar(aes(fill = Severity), position = "dodge") +
  scale_y_continuous(labels = percent) +
  theme(axis.text.x = element_text(angle = 60, vjust = 0.6))

p10 <- ggplot(cars, aes(Give_Way, ..prop.., group = Severity)) +
  geom_bar(aes(fill = Severity), position = "dodge") +
  scale_y_continuous(labels = percent) +
  theme(axis.text.x = element_text(angle = 60, vjust = 0.6))

p11 <- ggplot(cars, aes(Traffic_Calming, ..prop.., group = Severity)) +
  geom_bar(aes(fill = Severity), position = "dodge") +
  scale_y_continuous(labels = percent) +
  theme(axis.text.x = element_text(angle = 60, vjust = 0.6))


p12 <- ggplot(cars, aes(Bump, ..prop.., group = Severity)) +
  geom_bar(aes(fill = Severity), position = "dodge") +
  scale_y_continuous(labels = percent) +
  theme(axis.text.x = element_text(angle = 60, vjust = 0.6))


p1+ p2+ p3+ p4

p5+ p6+ p7+ p8

p9+ p10+ p11+ p12
```

We chose to not use multiple of the 47 variables that we considered weren't relevant to the analysis we were conducting. As we can see in the table, end latitude, end longitude's proportion of NA values are higher than 50%. Given the distribution of wind direction through the different severity levels, we decided that the variable is uninformative. The description, bump, traffic calming, give way, no exit, railway, roundabout, station, stop, amenity, street, zip code, country, turning loop, county and TMC code weren't informative either given the distribution between the severity categories or near-zero variance.


```{r, echo = TRUE}
traffic <-  traffic %>%
  rename("Distance" = `Distance(mi)`, "Temperature" = `Temperature(F)`, "Humidity" = `Humidity(%)`,
         "Pressure" = `Pressure(in)`, "Visibility" = `Visibility(mi)`, "Wind_Speed" = `Wind_Speed(mph)`, "Precipitation" = `Precipitation(in)`, "Wind_Chill" = `Wind_Chill(F)`)

traffic$Severity <- as.character(traffic$Severity)

traffic <-
  traffic %>%
  add_n_miss() %>%
  filter(n_miss_all == 0) %>%
  select(-n_miss_all)

traffic <- traffic %>%
  mutate("Status" = factor(ifelse(Severity == "3" | Severity == "4", "Severe", "Not Severe"),
                           levels = c("Not Severe", "Severe")))
```


In this section of data cleaning and pre-processing above, we renamed some of the variables that had their units of measurement for ease of use later in our modeling and for our shinyApp. We took out entries of data that had NAs. If this was a smaller dataset, this may have negatively impacted our analysis, but we don't believe this effected our analysis for this project because even after taking out some data, we had a lot left to work with. Another very important part of this section is that, we took the Severity variable that we are looking at and split it into two to make it into a Categorical variable called Status. Severities 1 and 2 were grouped in to be Not Severe and 3 and 4 were grouped as Severe in the Status variable. 

<br>


```{r, echo = TRUE}
traffic_time <- traffic %>%
  mutate(Duration = (End_Time - Start_Time)) %>%
  # accident duration should be positive
  filter(!(Duration < 0)) %>%
  separate(Start_Time, into = c("Date", "Time"), sep = " ") %>%
  mutate("Year" = str_sub(Date, 1, 4), "Month" = str_sub(Date, 6, 7), "Day" = str_sub(Date, 9, 10),
         "Wday" = as.character(wday(Date))) %>%
  mutate("Hour" = str_sub(Time,1,2)) %>%
  select(-c("Date", "Time", "End_Time")) %>%
  select(Severity, Year, Month, Day, Hour, Wday, Duration, everything())

```

In this section, we used the End_Time and Start_Time variables to come up with several other variables such as Duration, Date, Time, Year, Month, Day, Wday and Hour. 


```{r, echo = TRUE}
#Drop levels that have less than 20 observations
weather_to_drop <-
  traffic_time %>%
    count(Weather_Condition) %>%
    filter(n < 20) %>%
    select(Weather_Condition)

weather_to_drop <-
  weather_to_drop$Weather_Condition %>%
    unlist()

traffic_weather <- traffic_time %>%
  filter(!(Weather_Condition %in% weather_to_drop)) %>%
  mutate(Weather_Condition = factor(Weather_Condition))

traffic2 <- traffic_weather

count_city <- traffic2 %>%
  group_by(City) %>%
  summarize(Count=n()) %>%
  arrange(desc(Count)) %>%
  head(950)  

traffic3 <-
  traffic2 %>%
    left_join(count_city, by="City")

traffic_final <-
  traffic3 %>%
  add_n_miss() %>%
  filter(n_miss_all == 0) %>%
  select(-n_miss_all) %>%
  select(-Count)

#write.csv(traffic_final, "traffic_final.csv", row.names = FALSE)
```

```{r}
read_csv("traffic_final.csv")
```


Upon close examination of the Weather_Conditions variable, we realized that it had a lot of different observations and we wanted to narrow it down. So, we filtered and dropped levels that have less than 20 observations. We had to narrow down the City variable as well. We have over 4000 distinct cities under the top 12 states. Shiny only allows a thousand different observations and so in order for all the top cities to fit in our shiny app, we had to narrow down the list of cities to the top 950. 


```{r, echo = TRUE}
#modeling pre-process for traffic_final

traffic_mod <- traffic_final %>%
  mutate(Status = as.factor(Status)) %>%
  mutate(across(where(is.character), as.factor)) %>%
  select(-c(State, Severity, Year, Day)) %>%
  # select(-arrival_date_year,
  #        -reservation_status,
  #        -reservation_status_date) %>%
  add_n_miss() %>%
  filter(n_miss_all == 0) %>%
  select(-n_miss_all)


traffic_mod$Crossing <- as.factor(traffic_mod$Crossing)
traffic_mod$Month <- as.numeric(traffic_mod$Month)
traffic_mod$Wday <- as.numeric(traffic_mod$Wday)
traffic_mod$Hour <- as.numeric(traffic_mod$Hour)
traffic_mod$Duration <- as.numeric(traffic_mod$Duration)
traffic_mod$Junction <- as.factor(traffic_mod$Junction)
traffic_mod$Traffic_Signal <- as.factor(traffic_mod$Traffic_Signal)
 

set.seed(494) #for reproducibility

# Randomly assigns 75% of the data to training.
traffic_split <- initial_split(traffic_mod,
                             prop = .50)
traffic_split

traffic_training <- training(traffic_split)
traffic_testing <- testing(traffic_split)
```

Here, we get the data ready for the modeling part by taking the non-predictive variables out of our data set, and converting the predictors' data type into the correct type. After that, we split our data into testing and training data according to a 50 percentage split.

```{r, echo=FALSE}
#lasso
set.seed(494)

lasso_recipe <-
  recipe(Status ~ .,
         data = traffic_training) %>%
  # step_mutate(County,
  #              County = fct_lump_n(County, n = 5)) %>%
   step_mutate(City,
               City = fct_lump_n(City, n = 5)) %>%
  step_normalize(all_predictors(),
                 -all_nominal(),
                 -all_outcomes()) %>%
  step_dummy(all_nominal(),
             -all_outcomes())

lasso_recipe %>%
  prep() %>%
  juice()

lasso_mod <-
  logistic_reg(mixture = 1) %>%
  set_engine("glmnet") %>%
  set_args(penalty = tune()) %>%
  set_mode("classification")

lasso_wf <-
  workflow() %>%
  add_recipe(lasso_recipe) %>%
  add_model(lasso_mod)

set.seed(494) #for reproducible 5-fold
traffic_cv <- vfold_cv(traffic_training,
                       v = 5)

penalty_grid <- grid_regular(penalty(),
                             levels = 10)

# add ctrl_grid - assures predictions and workflows are saved
ctrl_grid <- control_stack_resamples()

metric <- metric_set(accuracy)

# tune the model
lasso_tune <-
  lasso_wf %>%
  tune_grid(
    resamples = traffic_cv,
    grid = penalty_grid,
    control = ctrl_grid
    )

lasso_tune %>%
  collect_metrics()


best_param <- lasso_tune %>%
  select_best(metric = "accuracy")
best_param

final_lasso <- lasso_wf %>%
  finalize_workflow(best_param) %>%
  fit(data = traffic_training)

final_lasso %>%
  pull_workflow_fit() %>%
  tidy()

```

The first model we build is a classification LASSO model, which selects the variables based on the magnitude of their coefficients. We tuned the LASSO model using a level 10 panelty grid, and selected the tuning parameter with the best prediction accuracy as the parameter for the final model. The accuracy for the best LASSO model is 80.956%, which means that the LASSO model predicts the right severity level 80.956% of the times. 

```{r, echo=FALSE}
#classification rf
set.seed(494)

rf_recipe <-
  recipe(Status ~ .,
         data = traffic_training) %>%
  step_mutate_at(all_numeric(),
                 fn = ~as.numeric(.))


rf_recipe %>%
  prep() %>%
  juice()


rf_model <-
  rand_forest(mtry = tune(),
              min_n = tune(),
              trees = 10) %>%
  set_mode("classification") %>%
  set_engine("ranger")


rf_workflow <-
  workflow() %>%
  add_recipe(rf_recipe) %>%
  add_model(rf_model)


rf_penalty_grid <-
  grid_regular(finalize(mtry(),
                        traffic_training %>%
                          select(-Status)),
               min_n(),
               levels = 3)


# traffic_cv <- vfold_cv(traffic_training,
#                        v = 5)

rf_tune <-
  rf_workflow %>%
  tune_grid(
    resamples = traffic_cv,
    grid = rf_penalty_grid,
    control = control_stack_grid()
  )

rf_tune %>%
  collect_metrics()
```

After conducting the LASSO model, we also build the random forest model, which builds 10 trees and gives out the mode of the predictions of these 10 trees. We thought that this model might be more accurate than the LASSO model although it is also more computationally inefficient. We used a panelty grid of level 3 to tune our random forest model, and the tuning parameter with the largest accuracy is with `mtry` = 12 and `min_n` = 40. The largest accuracy is 84.693%, which is higher than the LASSO model.

```{r, echo = TRUE}
#decision trees
set.seed(494)

tree_model <-
  decision_tree() %>%
  set_mode("classification") %>%
  set_engine("rpart")

tree_workflow <-
  workflow() %>%
  add_recipe(rf_recipe) %>%  
  add_model(tree_model)

tree_fit <-
  tree_workflow %>%
  fit_resamples(traffic_cv,
                # metrics = metric,
                control = control_stack_resamples()
  )

collect_metrics(tree_fit)
```
Finally, in order to create a stacked model, we build a third model which is just a simple classification decision tree. The accuracy for the decision tree model is 82.559%, which is also higher than the LASSO.


```{r, echo = TRUE}
# model stacking
lasso_tune %>%
  collect_metrics()

rf_tune %>%
  collect_metrics()

tree_fit %>%
  collect_metrics()
```


```{r, echo = TRUE}
traffic_stack <-
  stacks() %>%
  add_candidates(lasso_tune) %>%
  add_candidates(rf_tune) %>%
  add_candidates(tree_fit)
```

```{r, echo = TRUE}
traffic_blend <-
  traffic_stack %>%
  blend_predictions()
traffic_blend
```

```{r, echo = TRUE}
traffic_final_stack <- traffic_blend %>%
  fit_members()

#saveRDS(traffic_final_stack, "traffic_final_stacked.rds")
```




# Global interpretation

Global model interpretations explain the overall relationships between the predictor variables and the response.

### Model performance

```{r, echo = TRUE}
best_accuracy <-
  rf_tune %>%
  select_best(metric = "accuracy")

rf_final_mod <- rf_workflow %>%
  finalize_workflow(best_accuracy) %>%
  fit(data = traffic_training)

best_accuracy2 <-
  lasso_tune %>%
  select_best(metric = "accuracy")

lasso_final_mod <- lasso_wf %>%
  finalize_workflow(best_accuracy2) %>%
  fit(data = traffic_training)

best_accuracy3 <-
  tree_fit %>%
  select_best(metric = "accuracy")

tree_final_mod <- tree_workflow %>%
  finalize_workflow(best_accuracy3) %>%
  fit(data = traffic_training)
```

```{r, echo = TRUE}
rf_explain <-
  explain_tidymodels(
    model = rf_final_mod,
    data = traffic_training %>% select(-Status),
    y = traffic_training %>%
      mutate(status_num = as.integer(Status =="Severe")) %>%
      pull(status_num),
    label = "rf"
  )

lasso_explain <-
  explain_tidymodels(
    model = lasso_final_mod,
    data = traffic_training %>% select(-Status),
    y = traffic_training %>%
      mutate(status_num = as.integer(Status =="Severe")) %>%
      pull(status_num),
    label = "lasso"
  )

tree_explain <-
  explain_tidymodels(
    model = tree_final_mod,
    data = traffic_training %>% select(-Status),
    y = traffic_training %>%
      mutate(status_num = as.integer(Status =="Severe")) %>%
      pull(status_num),
    label = "tree"
  )
```

```{r, echo= FALSE}
rf_mod_perform <- model_performance(rf_explain)
lasso_mod_perform <- model_performance(lasso_explain)
tree_mod_perform <- model_performance(tree_explain)
```

```{r, echo = TRUE}
# hist_plot_lasso <-
#   plot(lasso_mod_perform,
#        geom = "histogram")
# box_plot_lasso <-
#   plot(lasso_mod_perform,
#        geom = "boxplot")
#
# hist_plot_lasso + box_plot_lasso

```

```{r, echo = TRUE}
# hist_plot_rf <-
#   plot(rf_mod_perform,
#        geom = "histogram")
# box_plot_rf <-
#   plot(rf_mod_perform,
#        geom = "boxplot")
#
# hist_plot_rf + box_plot_rf

```


```{r, echo = TRUE}
# hist_plot_tree <-
#   plot(tree_mod_perform,
#        geom = "histogram")
#
# box_plot_tree <-
#   plot(tree_mod_perform,
#        geom = "boxplot")
#
# hist_plot_tree + box_plot_tree
```

```{r}
plot(tree_mod_perform,lasso_mod_perform,rf_mod_perform,geom = "histogram")+
plot(tree_mod_perform,lasso_mod_perform,rf_mod_perform,geom = "boxplot")
```
As we can see from the histograms, the majority of the residual values are clustered in values close to 0. The model with the lowest average residual value is lasso, followed by the tree model and the forest model. While the lasso and the forest models are left skewed this is not the case for the classification tree. The residuals for the classification tree are more spread towards the positive and the negative values, showing that this model might be less precise than the other two.

### Variable of importance

```{r}
set.seed(494)

lasso_var_imp <-
  model_parts(
    lasso_explain
    )

plot(lasso_var_imp, show_boxplots = TRUE)

```

```{r}
set.seed(494)
rf_var_imp <-
  model_parts(
    rf_explain
    )

plot(rf_var_imp, show_boxplots = TRUE)
```


```{r}
set.seed(494)
tree_var_imp <-
  model_parts(
    tree_explain
    )

plot(tree_var_imp, show_boxplots = TRUE)
```

We can see that there are more variables with greater importance in the lasso and the forest models. This means that, the values that are at the top generate great increases in the performance of the model when permuted relative to the other variables. The length of the bars indicate how much the performance increases when that variable is permuted. Permuting is the process of exchanging the values of a variable between observations. We can see that the lasso and forest model's performance increase when start longitude is permuted. This is the case for city in the classification tree.

### Ceteris-Paribus Profile

This profiles show how one variable affects the outcome holding all other variables fixed for one observation.

```{r}
cp_profile <- function(explainer, obs, var){
  cpp<-predict_profile(explainer = explainer, new_observation = obs, variables = var)
  cpp %>%
    filter(`_vname_` %in% c(var)) %>%
  ggplot(aes_string(x = var,
             y = "`_yhat_`")) +
  geom_line()
}
 
obs37 <- traffic_training %>%
  slice(37)

cp_profile(rf_explain, obs37, "Start_Lng")
cp_profile(lasso_explain, obs37, "Start_Lng")
cp_profile(tree_explain, obs37, "Start_Lng")
```

In this graph we can see how changes to the values of the starting longitude affect the probability that the accident is Severe, holding all the other variables constant. As we can see, the probability that an accident is severe changes drastically whit different start longitude values, reflecting the importance of the variable for the forest model.

### Partial Dependence Plots

Remember the CP profile used only one observation? A partial dependence plot is created by averaging the CP profiles for a sample of observations. The partial dependence profile is the blue line. We can see that overall, changes to the value of the longitude affect the probability that an accident is sever significantly. If we were to analyze the dependence plot for lasso the lines we would see inclined parallel lines given that lasso is additive. This is not very informative, that's why we decided to focus on the forest model.

```{r}
set.seed(494)

rf_pdp <- model_profile(explainer = rf_explain)

plot(rf_pdp,
     variables = "Start_Lng",
     geom = "profiles")
```


# Local Model Interpretation

Local model interpretation helps us understand the impact of variables on individual observations. We will focus on the random forest model given that it is the model with the higher accuracy. We would like to do the interpretation for the stacked model, but this isn't possible using DALEX and DALEXtra. Considering that out stacked model has few models stacked, we think that doing the analysis of the random forest model should give us a fair idea of what is the local importance of our variables.


### Shapley Additive Explanations (SHAP)

For Break Down profiles, the contributions of variables would change with the order in which the variables are considered in the random forest model. Therefore we decided to use the SHAP.


```{r, cache = TRUE}
rf_shap <-predict_parts(explainer = rf_explain,
                        new_observation = obs37,
                        type = "shap",
                        B = 10 #number of reorderings - start small
)

plot(rf_shap)
```

Each bar shows the average contribution of each variable's value to the predicted severity for this observed accident. We can see that a duration of 44.62 contributes almost an additional 0.15 to the predicted probability of a severe accident, on average. The boxplot shows the variation across permutations of the order of the variable. A large variation would mean that we should be less confident in its exact effect. For example we see that Nautical twilight has a large variation; therefore, we aren't confident about it's contribution to the prediction.


### Local Interpretable Model-agnostic Explanations (LIME)


```{r}
set.seed(494)

model_type.dalex_explainer <- DALEXtra::model_type.dalex_explainer
predict_model.dalex_explainer <- DALEXtra::predict_model.dalex_explainer

lime_rf <- predict_surrogate(explainer = rf_explain,
                             new_observation = obs37 %>%
                               select(-Status),
                             n_features = 5,
                             n_permutations = 1000,
                             type = "lime")

lime_rf %>%
  select(model_r2, model_prediction, prediction) %>%
  distinct()

plot(lime_rf) +
  labs(x = "Variable")
```

The table shows the predicted value from the local model as 0.2624304. and the prediction from the original forest model of 6.17 This graph shows us the predicted value from the original random forest model as "Prediction". The r-squared value of the model is shown as the "Explanation fit" showing that the model explains 25% of the variance of our sample. The bars show that distance is the most important variable in the local model.
 

# Conclusion:

We have explored how changes in the values of variables for an observation can affect the predicted outcome using two methods. Both methods show similar results; however, it's important to note that while the SHAP plot includes more variables, it is less reliable. We have seen also that starting longitude is the most important variable according to two of our models, and that changing its value for an observation holding the other variables constant changes the predicted value significantly. Even with slight differences all of the models showed similar results for the variables of interest, showing that the results are coherent and reasonable. We can conclude that overall, distance, starting longitude, duration and month are the most important variables for the prediction of the severity of an accident. This means that depending on the month, the weather or the amount of traffic could be associated with the severity of an accident. The length of the road extent affected by the accident also is a good predictor for severity. The time between the start of the accident and the end of the impact on traffic flow also are associated with the severity. Lastly, there is a strong association between starting longitude of the accident and the severity which could be driven by demographic or other non-controlled characteristics that differentiate western to eastern states.


# Repercussions:

Our analysis only focused on environmental factors that are associated with the severity of an accident. There are multiple other factors that we didn't include like speed or whether the driver was intoxicated. Therefore, the model and the analysis is not complete and should not be regarded as such. On the other hand, this analysis didn't account for demographics; therefore, the differences in locations do not respond to anyone's ethnicity, education, sex or any other identity. This model is meant to further analyze what external factors contribute the most to the severity of an accident.


